---
title: "Introduction to R"
subtitle: "Written by Gordon Custer 2018"
output: html_notebook
---
#Introduction
For many of you this is your first experience with R. The goal of this exercise is to familiarize you with the basics of R and R Studio. In the processes we hope that this tutorial will help you overcome the anxiety that exists when trying to learn something new. First off, What is R? R is both a programming language and software environment for statistical computing and visualization. The benefit of R versus some other statistical computing software packages is that R is totally free and can be downloaded to any computer. This means if you are working for the forest service in a small office in the middle of nowhere, you don't have to convince your boss to purchase a $10,000 subscription of SPSS. R is available for free! As for R studio, R studio offers a GUI (Graphical User Interface) with drop down menus, and handy visualizations for key features. R does the work; R studio makes it pretty. 

#Getting Started
After opening R studio you will see 4 panes (maybe 3, meaning one is hidden and we can fix that). These four panes are as follows and their locations are given based upon the defaults of R Studio. You can change this if you prefer an alternate set up. 
      1. Source (Top Left). This pane contains the script you are working on.
      2. Console (Bottom Left). This pane contains a history of the commands you have ran. You can also code directly in this pane. 
      3. Environment/History (Top Right). The environment contains data which R can access at this given moment. The history tab contains a history of the code you have ran. 
      4. The final pane (Bottom Left) contains several tabs. In this pane, you can view graphs, search for files, install packages (we will get to this in a minute), and even find documentation on packages or functions. This pane is your friend. Become comfortable with it. 
      
#Opening a script and saving
Any experienced R user will tell you one of the benefits of using a program such as R is the ability to write code once and "reuse" it over and over again with slight modifications. This allows you to run an analysis for a collaborator (or yourself) and save it until next year when they ask you to do the same thing again. As mentioned above, you could type directly into the console, but this would only save your work flow until you exit the window. In order to save your work for future analyses programming into a notebook or script is highly recommended. For example, this R script is written in a special kind of notebook known as markdown. This format, which is different from an R script, allows programmers to include text, figures, headings, and code all in the same place. In addition, this notebook can be rendered in a .html format so anyone with a web-browser can access it. On the other hand the simplest way to keep a copy of your program or code is to use the R-script option. There are several other options as well but for the sake of simplicity we will only look at these two. For your first task, lets further explore the two options discussed above. 

Exercise 1: Navigate to the "File" drop down menu in the toolbar. Click "New File", and open first a "R Script" and then open a "R Notebook". What do you notice about initial appearances? Answer this question in the lab handout. Go to the R Notebook, and run the default script that is displayed in the greyed-out area. The code displayed at the beginning ```{r} and at the end ``` is just used to indicate the start and end of the R code in the R Notebook, and should not be copied into the R script. Copy and past the code into the basic R Script file you just created and run the script by highlighting the whole script and pressing *Cmd+Enter*. What is different between the two file type with respect to where the figure appears? Answer this question in the labhandout.

Now, lets see what a co-worker would see if you supplied them a copy of your R Notebook in .html format. Go back to your R notebook you just created. On the top of the "Source" pane (top left pane), there is a small button "R Preview". Make sure you have run the plot(cars) command. Then click this preview option. The preview option will prompt you to save this script. Save it in your "ECOL5540" folder on the Desktop. It is good practice to save scripts with a descriptive name so you can find it easily at a later date; name this file "ScriptTest_Rnotebook". Once, the notebook has rendered, open the html file from your Finder window, and you will see the plot(cars) graph embedded in the document. In addition you can show or hide the code which was used to produce this graph by clicking "hide" to the right of the R scripts. While this example is very simple, the same holds true for more complex analysis. 

#Installing a package
Before we get into data manipulation let's quickly go over how to install a package and load it in your current session. Simply put, a package is a collection of programs or functions which might not be included in basic install of R. This is also known as base R. Installation of packages allows for users to access functions and run analyses without having to write all of the code themselves. The data set used below actually comes included in the "Faraway" package. In order to load a package, you must first install it. You only need to install a package once but you may have to load it many times. Below you will find two lines which will help you install any given package. Notice the quotations around the name of the package faraway; without them the function will not work. Run the script below to install the faraway package. Check your console pane at bottom left, as you may get the following message:
"Do you want to install from sources the packages which need compilation? y/n:"
If so, type y and press enter to continue the installation.
 

```{r}
#this line downloads the package to your machine
install.packages("faraway")
#this line loads the package into your current session
require(faraway)
#this lets you see what packages you have loaded at the moment
(.packages())
```

While this package loaded relatively quickly some packages take hours to successfully download and install. One such package, DADA2, which we will use later, takes several hours and requires many dependencies to run successfully. This package will be installed for you prior to next week.   

Exercise 2. Find the 'lubridate' package by going to the "packages" tab in the bottom right pane. Click on Install and search for 'lubridate' in the search bar named "packages". Make sure that the "Install dependencies" box is checked, and click "Install". Again, type 'y' if you get the following message in your console pane: "Do you want to install from sources the packages which need compilation? y/n:". Explore some of the functions included in the 'lubridate' package. Go to the "Packages" tab in the bottom right pane, and in the search bar type lubridate. The package name should come up in the list. Click on the name of the package which is a link to the help page. What can you do with this package? Answer this question in the labhandout.

A tip that will come in handy nearly every time you are using R is that you can always Google your problem!! We will get into this in more detail here shortly. But for now, if you ran "install.packages("DADA2")" nothing would install. That is because the DADA2 package isn't available on the CRAN repository. This package is available through bioconductor. Many packages (>1500) which are extremely useful in the analysis of high throughput genomic data are found on bioconductor. This is a great example of the flexibility of R. Below is a link to the installation guide for DADA2. We will start this installation today. Look at the link below for a detailed walk through on the installation of DADA2.

https://benjjneb.github.io/dada2/dada-installation.html

We will start working with DADA2 next week. Before you start using any program, such as DADA2, it is best to familiarize yourself with the associated literature. https://benjjneb.github.io/dada2/index.html will direct you to the DADA2 github page and you can find publications and other information pertaining to DADA2. Please look over this page and come with any questions you may have.


#Familiarizing yourself with your working environment. 
Your working environment and working directory are extremely important when you want to read in data or save an analysis. Imagine you are in your office; this is your working directory. You can write on a piece of paper and save it on your desk. You can also find notes which you left yourself. You are able to easily access anything in your office. Your neighbors office, while located in the same hallway, requires you to back out of your office and then enter his. This analogy holds true for finding files on your computer too. Your working environment will allow you to access files quickly and to write copies of your analysis or environment easily. Like you can walk into your co-workers office, you can change your working directory to access a different set of files. 

As an example, lets download the file named "pima.csv" and save it in your folder on the Desktop. 
Go to the website below to access the file:
https://github.com/gcuster1991/Micro_Div

We want to read in the file 'pima.csv' and see what happens when we specify the wrong location. Up until now all text has been written outside of a block of code. In order to add comments, which is a really good, I mean really good, habit to get into you only need to add a "#" before any line you do not wish R to interpret. In the code below (lines 60-67) you can see certain lines are not interpreted even if you ran the block as a whole. These comments will not show up in your rendered .html notebook either. You have to open the notebook in R studio to access these comments. 

Here (lines 60-67) we have our first block of code, also referred to as a "chunk". Anything in here can be ran by clicking the green play button in the top right corner of the block. In addition, we can # out this block by placing a "#" before the r in the ```{r}. The keyboard shortcut for inserting a new block of code is "Command" + "Option" + "i". Run the code below. 

```{r}
#R will not interpret this line due to the # at the begining
#Lets see where we are right now (our current working directory)
getwd()
#Now lets say we want to change our working directory to the Downloads folder on your machine. This will only change the working directory in this chunk of code. Once this chunk finishes running your working directory will revert to whatever it was prior to running this chunk.
setwd("/Users/gordoncuster/Downloads/")
```
You will get an error message 'cannot change working directory'.

Exercise 3: Insert a new chunk below. Then, write the correct code to change the working directory to your folder on the Desktop of your computer that your created at the beginning of lab, and write the code to get what your current directory is. Run the whole code and copy the whole code you created to the exercise 3 location in your lab handout.

#Loading data
Now lets try to read in our data (pima.csv). In order to do so, we need to make sure we are in the correct working directory and the file exists. You can do this by using the getwd() command and making sure the file exists in that location. 

Below are two lines of code which read in the data set. However, there is one slight difference. Run code 1 first, then run code 2.
```{r}
#Code 1
read.csv("Pima.csv")
```
Code 2 
```{r}
#Code 2
Pima<-read.csv("Pima.csv")
```
Exercise 4: What is the difference and what does it do?  Answer this question in the labhandout. Next, run the code below (lines 89-91). What happened when you forget to include the "" around the file name? Answer this question in the labhandout. Next, run the code below (lines 92-95). What happens when your working directory is changed back to the "Downloads" file? Answer this question in the labhandout.

```{r}
Pima<-read.csv(Pima.csv)
```

```{r}
setwd("/Users/gordoncuster/Downloads/")
Pima<-read.csv("Pima.csv")
```
Exercise 5: A final consideration for reading files in is to specify the entire path to the file. This is often the safest way to operate because it doesn't matter where your working directory is set. You can find a file no matter where it is on your computer. Run the code below (lines 98-100), which is an example of how to specify the entire pathway to a file on my desktop. Copy the error message to your lab handout in the exercise 5 location. 
```{r}
Pima<-read.csv("/Users/gordoncuster/Desktop/pima.csv")
```
Next, insert a new chunk below and write the correct code to read in the Pima.csv file using the entire pathway to your folder on your Desktop. Run the code to see if there are no error messages and then copy the code to your lab handout in the exercise 5 location. 

R will yell at you. Get used to it. It happens all the time. Learn to embrace it and you will be well on your way to solving any problem R can throw at you. Did you notice that the symbol "<-" saves what ever is to the right as a variable named what you have to the left of the symbol "<-". This can be extremely useful when selecting a subset of a data frame or running an analysis. You don't want to have to re-run it every time. By saving it to a new variable you can access it whenever you wish. 

Tip: Help pages. Under the Help tab in the bottom right pane, type "read.csv" in the search bar on the right. This page will tell you everything that the function read.csv (well actually read.table) requires and can do. Become familiar with these pages and you can avoid many head aches. Each page provides a brief description of the function, the usages, required arguments, outputs (values), and a short example snippet of code.

Exercise 6: Copy the description, that appeared in your help pane after you searched for "read.csv", to your lab handout in the exercise 6 location. 

Now that our data is read in, lets see what it looks like. We can do this several ways. Below are several ways to look at the data. Look at each of the different types of data display by running the codes.  
```{r}
#Code 1, just the name of the data file, will give you an overview of what the data looks like for all your columns.
Pima
```

```{r}
#Code 2: the word 'str' in this code will display the structure of the data; data type, number of observations and variables and variable type
str(Pima)
```

```{r}
#Code 3 will give you a summary of the data, with min, median, max values of each variable.
summary(Pima)
```

Exercise 7: Look at the output from str(Pima). The data structure of Pima is a data.frame. What other types exist? Use Google and look for other data types. Answer this question in the labhandout. The type of data is an important point because some functions in R require a certain type of data. 

What if you need another type of data? Some functions which are extremely useful for converting among data types are as.data.frame and as.matrix. 
Exercise 8: Convert the Pima data.frame to a matrix, using the code below, and then check its structure. Copy the info displayed of the structure to your lab handout in the exercise 8 location. Once you have done this convert the Pima matrix back to a data.frame, using the second code below. 

```{r}
#The code as.matrix will convert your dataframe to a matrix
Pima<-as.matrix(Pima)
str(Pima)
```

```{r}
#The code as.data.frame will convert your matrix back to a data frame again 
Pima<-as.data.frame(Pima)
Pima$test<-as.factor(Pima$test)
str(Pima)
```
After you have converted the Pima matrix back to a data.frame check its structure again. You will see that each variable has a data type associated with it. In our Pima data.frame we have 6 integer (int), 2 numeric (num), and 1 factor (factor).  What do some of these things mean (character vs. numeric vs. factor)? Numeric and integers are ways of encoding numeric data. The big difference is that integers can not have decimals while numeric variables can. Factors are a good way of including categorical data. As you can see the test column is a factor with two levels. The levels correspond to a positive or negative test for diabetes.

#Working with data
In the code below we introduce an easy way to pull out a single column from a data set. Run the full code and take a look at the resulting figures. As you will see, the "$" operator allow you to select a single column. 
```{r}
# The first line of code will display all variables in various plots, the second line will plot only the diastolic variable, and the third code line will result in a histogram of the variable diastolic.
plot(Pima)
plot(Pima$diastolic)
hist(Pima$diastolic)
```
Exercise 9: Suppose you wanted to select several columns. Lets say columns 1-5. What would you do? Let's use this opportunity to try Googling your problem. This is another useful skill to master. If you can put your problem in the correct terms, it is very likely someone else has faced the same difficulty and will be able to help.  Search Google for the answer to this problem. I would say start Googling something like "Program R select multiple columns" or "subset data frame to only include certain columns Program R". As you can see from these two suggestions, the exact verbiage isn't that important. Copy your final code to your lab handout in the exercise 9 location, as well as the first line of the resulting display of the data structure using the 'str' command.

```{r}
#Type your code in the next line that will create a subset of the data set with just columns 1 through 5 selected. Then run the full code, and by using str(subset_Pima), you can check if you did correctly selected the 5 columns.

str(subset_Pima)
```
Hopefully you found out that the square brackets work such that numbers before the comma indicate rows (by leaving this blank we are telling the program we want all rows) and numbers occurring after the comma indicate columns. Above, we are saying we want only columns 1:5. The c() concatenates this selection. We could also include columns that are not next to each other by writing our brackets to look something like this [,c(1:4, 7)]. This would only select columns 1, 2, 3, 4, and 7. 

Another way to do this would be to make a vector of the column names you wish to keep. Lets use the following block to walk through these steps. Here we introduce a new function, unique. The unique function runs through what ever the input may be and prints each unique value present in the vector or data frame. This function can be very useful. 
```{r}
unique(colnames(Pima))
#Let's now only pull out the columns "glucose", "diabetes", and "bmi". In order to do so lets make a vector containing these values.
columns_to_keep<-c("glucose", "diabetes","bmi")
subset_Pima<-Pima[,colnames(Pima) %in% columns_to_keep]
str(subset_Pima)
```
Exercise 10: Can you interpret what is going on in the before last line of code? Try to put it into plain English. Hint %in% reads as "found in". 

Exercise 11: Insert a new chunk of code (don't remember how do do this, see line 58) and write a code that will pull only the first two rows of the columns "age" and "triceps". Copy your final code to your lab handout in the exercise 11 location.

Something to keep in mind is that there are several ways to accomplish the same feat. As of now we have used base R to subset data. A very valuable suite of tools in R come in the Tidyverse package. 

Install the tidyverse package and load it for use. The chunck below only includes the code to load the package (library(tidyverse)). Can't remember how to install a package, see lines 29-36.
```{r}

library(tidyverse)
```

Some very useful functions available through the tidyverse package are filter, select, mutate, group_by, gather, join, summarize, and spread. Also available through the tidyverse is the "%>%". This symbol is called a pipe. The pipe allows you to string together functions instead of breaking them up into individual lines of code. Below is an example of how to run a line individually and then an example of how to string together tidyverse functions using the pipe symbol.

```{r}
#Suppose you wanted to keep all subjects with a glucose level under 100. You could use the fliter funciton
filter(Pima, glucose <= 100)
#Now suppose you wanted to get the mean blood glucose value for individuals with diabetes and individuals without diabetes. 
Pima %>%
  group_by(test) %>%
  summarize(mean_glucose = mean(glucose, na.rm = TRUE))
```
Exercise 12: Filter pima to only include the individuals that are over 25. Then get the average B.M.I. for both the positive and negative test groups. Copy your final code to your lab handout in the exercise 12 location, as well as the mean glucose values for each test group.

Answer:
```{r}
Pima %>% filter(age>25) %>%
  group_by(test) %>%
  summarize(mean_glucose = mean(glucose, na.rm = TRUE))
```
The tidyverse offers a wide array of functions that can make your life easier. It would be wise to familiarize yourself with these functions and make use of them in the future. 

Before we call it quits today, lets take this opportunity to practice with some data manipulation in R. In a couple week or so you will be analyzing data collected by a student for their Master's project. In order to determine the effect of treatment we need to make sure we assign the correct data to the correct sample. To accomplish this we want to create a metadata sheet. A metadata sheet will contain all the data collected about each sample. Provided to you is a copy of the excel sheet "Metadata.csv". This sheet contains the site's ID, pH, EC, water content, enzyme values, and C:N. From the name we want to extract the other important information and include this in the metadata in a more explicit form. For example, the site name H11B actually means, the sample was collected from a healthy stand (H), it is the first sampling time (1), site 1 of 5 for healthy stands (1), and it is the bulk soil component (B). In this section we will examine how to pull out data and make our own metadata sheet for further analysis.

Exercise 13: Download the Metadata.csv sheet from GitHub (see line 54) and read it into R (don't remember how, go back to line 74). Copy the code you used to load the data to your lab handout in the exercise 13 location.

First we need to create a column named Soil. This column will tell us whether the sample was collected from the bulk or rhizosphere component. 
```{r}
#look up the command substr() in the seach bar of the help tab in bottom right pane for more info on this command. Using the command below, you will create a new column named Soil (metadata$Soil) at the end of your current dataset metadata. The column will be created based on the 4th character (start = 4, stop = 4) of the values in your Sample_ID column (metadata$Sample_ID). 
metadata$Soil<-substr(metadata$Sample_ID, start = 4, stop = 4)
#Using the code below you can check to see if the column Soil was added, and what the values are, which should be either A or B.
metadata
```

```{r}
#Next, we create and index with the values currenty in the column; A and B
index <- c("A", "B")
#Then we identify the values that we wish to insert in the place of the "index", which are Rhizosphere for A and Bulk for B.
values <- c("Rhizosphere", "Bulk")
metadata$Soil<- values[match(metadata$Soil, index)]
#And again, we can check to see if the column Soil was added, and what the values are now, which should be either Rhizosphere or Bulk.
metadata
```

Exercise 14: Create a column called "Infestation_Stage". This is designated by the first character in the Sample_ID. H means the sample was collected from a healthy stand, I from an infested stand, and D from a dead stand. In the newly created column "Infestation_Stage" the letter pulled from the first character of the Sample_ID should then be replaced with "Healthy", "Infested", or "Dead". Use the code in the previous sections above (lines 216-231) as a template for writing this new code. 
Copy the full code you used to your lab handout in the exercise 14 location.
Answer:
```{r}
```

Lets look at our newly minted metadata sheet.
```{r}
View(metadata)
```

Exercise 15: Save your new metadata file as a .csv to your desktop folder. Save it as a new file from the one your downloaded, i.e. change the name. Copy the full code you used to your lab handout in the exercise 15 location.
```{r}
#code to use to write the new metadata file to your folder on the Desktop, remember, change the path to the file so that it will be saved in the correct folder on your Desktop
write.csv(metadata,"/Users/LvanDiepen/Documents/teaching/Microbial div & ecology/2018/labs/HTS/Micro_Div-master/metadata_final.csv")
```

Lastly, suppose you are working with a huge data set. For many of you this will be the case. In order to avoid having to read in your data each and running time consuming code each and every time we can save your environment and reload it when you want to come back. To do so, look in the upper right pane under the environment tab. The save icon here will save your environment. 

Exercise 16: Save your working environment for use at a later date. Empty your environment by clicking on the "broom" symbol in the upper right pane under the environment tab and reload your saved data to make sure you are comfortable with this skill. For Reloading: click the "open folder" symbol in the upper right pane under the environment tab.

Citations and Resources:
1: https://www.r-project.org/ 
2: https://benjjneb.github.io/dada2/index.html
3. https://www.bioconductor.org/