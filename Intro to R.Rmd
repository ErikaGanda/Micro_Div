---
title: "Introduction to R"
subtitle: "Written by Gordon Custer 2018"
output: html_notebook
---
#Introduction
For many of you this is your first experience with R. The goal of this exercise is to familiarize you with the basics of R and R Studio. In the processes we hope that this tutorial will help you overcome the anxiety that exists when trying to learn something new. First off, What is R? R is both a programming language and software environment for statistical computing and visualization. The benefit of R versus some other statistical computing software packages is that R is totally free and can be downloaded to any computer. This means if you are working for the forest service in a small office in the middle of nowhere, you don't have to convince your boss to purchase a $10,000 subscription of SPSS. R is available for free! As for R studio, R studio offers a GUI (Graphical User Interface) with drop down menus, and handy visualizations for key features. R does the work; R studio makes it pretty. 

#Getting Started
After opening R studio you will see 4 panes (maybe 3, meaning one is hidden and we can fix that). These four panes are as follows and their locations are given based upon the defaults of R Studio. You can change this if you prefer an alternate set up. 
      1. Source (Top Left). This pane contains the script you are working on.
      2. Console (Bottom Left). This pane contains a history of the commands you have ran. You can also code directly in this pane. 
      3. Environment/History (Top Right). The environment contains data which R can access at this given moment. The history tab contains a history of the code you have ran. 
      4. The final pane (Bottom Left) contains several tabs. In this pane, you can view graphs, search for files, install packages (we will get to this in a minute), and even find documentation on packages or functions. This pane is your friend. Become comfortable with it. 
      
#Opening a script and saving
Any experienced R user will tell you one of the benefits of using a program such as R is the ability to write code once and "reuse" it over and over again with slight modifications. This allows you to run an analysis for a collaborator (or yourself) and save it until next year when they ask you to do the same thing again. As mentioned above, you could type directly into the console, but this would only save your work flow until you exit the window. In order to save your work for future analyses programming into a notebook or script is highly recommenced. For example, this R script is written in a special kind of notebook known as markdown. This format, which is different from an R script, allows programmers to include text, figures, headings, and code all in the same place. In addition, this notebook can be rendered in a .html format so anyone with a web-browser can access it. On the other hand the simplest way to keep a copy of your program or code is to use the R-script option. There are several other options as well but for the sake of simplicity we will only look at these two. For your first task, lets further explore the two options discussed above. 

Exercise: Navigate to the "File" drop down menu. Click "New File", and open both an "R Script" and an "R Notebook". What do you notice about initial appearances. Run the default script in the R Notebook, then run the same script in the basic R Script. Notice where the figure appears. 

Now, lets see what a co-worker would see if you supplied them a copy of your R Notebook in .html format. On the top of the "Source" pane, there is a small button "R Preview". Make sure you run the plot(cars) command first. Then click this preview option. The preview option will prompt you to save this script. Save it in your folder on the Desktop. It is good practice to save scripts with a descriptive name so you can find it easily at a later date. Once, the notebook has rendered, you will see the plot(cars) graph embedded in the document. In addition you can show or hide the code which was used to produce this graph. While this example is very simple, the same holds true for more complex analysis. 

#Familiarizing yourself with your working environment. 
Your working environment and working directory are extremely important when you are wanting to read in data or save an analysis. Imagine you are in your office; this is your working directory. You can write on a piece of paper and save it on your desk. You can also find notes which you left yourself. You are able to easily access anything in your office. Your neighbors office, while located in the same hallway, requires you to back out of your office and then enter his. This analogy holds true for finding files on your computer too. Your working environment will allow you to access files quickly and to write copies of your analysis or environment easily. Like you can walk into your co-workers office, you can change your working directory to access a different set of files. 

As an example, lets download the file named "pima.csv" and save it in your folder on the Desktop. 

https://github.com/gcuster1991/Micro_Div

We want to read in the file and see what happens when we specify the wrong location. Up until now all text has been written outside of a block of code. In order to add comments, which is a really good, I mean really good, habit to get into you only need to add a "#" before any line you do not wish R to interpret. In the code below you can see certain lines are not interpreted even if you ran the block as a whole. These comments will not show up in your rendered .html notebook either. You have to open the notebook in R studio to access these comments. 

Here we have our first block of code, also referred to as a "chunk". Anything in here can be ran by clicking the green play button in the top right corner of the block. In addition, we can # out this block by placing a "#" before the r in the ```{r}. The keyboard shortcut for inserting a new block of code is "Command" + "Option" + "i".

```{r}
#R will not interpret this line due to the # at the begining
#Lets see where we are right now (our current wokring directory)
getwd()
#Now lets say we want to change our working directory to the Downloads folder on your machine. 
setwd("/Users/gordoncuster/Downloads/")
#In order to make sure the computer knows what its looking for use the "Tab" key. This functions as an autocomplte. If the computer is unable to autocomplte you know you have done something wrong. 
```
Exercise: Insert a new chunk below. Then, change the working directory to your folder on the Desktop of your machine. 

Now lets try to read in our data (pima.csv). In order to do so, we need to make sure we are in the correct working directory and the file exists. You can do this by using the getwd() command and making sure the file exists in that location. 

Below are two lines of code which read in the data set. However, there is one slight difference. What is the difference and what does it do? What happens if you forget to include the "" around the file name? What happens if you change your working directory back to the "Downloads" file and try to run the same script? 
```{r}
read.csv("Pima.csv")
Pima<-read.csv("Pima.csv")

Pima<-read.csv(Pima.csv)

setwd("/Users/gordoncuster/Downloads/")
Pima<-read.csv("Pima.csv")
```

R will yell at you. Get used to it. It happens all the time. Learn to embrace it and you will be well on your way to solving any problem R can throw at you. Did you notice "<-" saves what ever is to the right as a variable named what ever you have to the left of the "<-". This can be extremely useful when subset ting a data frame or running an analysis. You don't want to have to re-run it every time. By saving it to a new variable you can access it whenever you wish. 

Tip: Help pages. Under the Help tab, type "read.csv". This page will tell you everything that the function read.csv (well actually read.table) requires and can do. Become familiar with these pages and you can avoid many head aches. Each page provides a brief description of the function, the usages, required arguments, outputs (values), and a short example snippet of code. 

Now that our data is read in, lets see what it looks like. We can do this several ways. Below are several ways to look at the data. What are some of the key differences? 

```{r}
Pima
str(Pima)
summary(Pima)
plot(Pima)
plot(Pima$diastolic)
hist(Pima$diastolic)
```
In the section above we introduced an easy way to pull out a single column from a data set. The "$" operator allow you to select a single column. Suppose you wanted to select several columns. Lets say columns 1-5. What would you do? Let's use this opportunity to try Goggling your problem. This is another useful skill to master. If you can put your problem in the correct terms, it is very likely someone else has faced the same difficulty and will be able to help. 

Exercise: Search Google for the answer to this problem. I would say start Googling something like "Program R select multiple columns" or "subset data frame to only include certain columns Program R". As you can see from these two suggestions, the exact verbiage isn't that important. 

Answer: 
```{r}
subset_Pima<-Pima[,c(1:5)]
```
Hopefully you found out that square brackets work such that numbers before the comma indicate rows (by leaving this blank we are telling the program we want all rows) and numbers occurring after the comma indicate columns. Above, we are saying we want only columns 1:5. The c() concatenates this selection. We could also include columns that are not next to each other by writing our brackets to look something like this [,c(1:4, 7)]. This would only select columns 1, 2, 3, 4, and 7. 

Another way to do this would be to make a vector of the column names you wish to keep. Lets use the following block to walk through these steps. Here we introduce a new function, unique. The unique function runs through what ever the input maybe and prints each unique value present in the vector or data frame. This function can be very useful. 
```{r}
unique(colnames(Pima))
#Let's only pull out the columns "glucose", "diabetes", and "bmi". In order to do so lets make a vector containing these values.
columns_to_keep<-c("glucose", "diabetes","bmi")
subset_Pima<-Pima[,colnames(Pima) %in% columns_to_keep]
```
Can you interpret what is going on in the last line of code? Try to put it into plain English. Hint %in% reads as "found in".

Exercise: Insert a new chunk and pull only the first two rows of the columns "age" and "triceps".

OK, now that we have introduced some of the basic concepts for data manipulation, let's quickly run over how to install a package and load it in your current session. Simply put, a package is a collection of programs or functions which might not be included in base R. Installation of packages allows for users to access functions and run analyses without having to write all of the code themselves. The data set used above actually comes included in the "Faraway" package. In order to load a package, you must first install it. You only need to install a package once but you may have to load it many times. Below you will find two lines which will help you install any given package. Notice the quotations. Much like above, in the read.csv block, the function will not work if you do not have the proper syntax. 

```{r}
#this line downloads the package to your machine
install.packages("faraway")
#this line loads the package into your current session
require(faraway)
#this lets you see what packages you have loaded at the moment
(.packages())
```

While this package loaded relatively quickly some packages take hours to successfully download and install. One such package, DADA2, which we will use later, takes several hours and requires many dependencies to run successfully. At the end of this exercise we will install this so it is ready for us to being using at the beginning of next class.  

Exercise. Find a package online that interests you, install it and load it. Explore some of the functions included in the package. 

As I mentioned earlier, you can always Google your problem. If you ran "install.packages("DADA2")" nothing would install. That is because the DADA2 package isn't available on the CRAN repository. This package is available through bioconductor. Many packages (>1500) which are extremely useful in the analysis of high throughput genomic data are found on bioconductor. This is a great example of the flexibility of R. Below is a link to the installation guide for DADA2. We will start this installation today. Look at the link below for a detailed walk through on the installation of DADA2.

https://benjjneb.github.io/dada2/dada-installation.html

We will start working with DADA2 next week. Before you start using any program, such as DADA2, it is best to familiarize yourself with the associated literature. https://benjjneb.github.io/dada2/index.html will direct you to the DADA2 github page and you can find publications and other information pertaining to DADA2. Please look over this page and come with any questions you may have.

Before we call it quits today, lets take this opportunity to practice with some data manipulation in R. In a couple week or so you will be analyzing data collected by a student for their Master's project. In order to determine the effect of treatment we need to make sure we assign the correct data to the correct sample. To accomplish this we want to create a metadata sheet. A metadata sheet will contain all the data collected about each sample. Provided to you is a copy of the excel sheet "Metadata.csv". This sheet contains the site's ID, pH, EC, water content, enzyme values, and C:N. From the name we want to extract the other important information and include this in the metadata in a more explicit form. For example, the site name H11B actually means, the sample was collected from a healthy stand, it is the first sampling time, site 1 of 5 for healthy stands, and it is the bulk soil component. In this section we will examine how to pull out data and make our own metadata sheet for further analysis.

Exercise: Download the Metadata.csv sheet from GitHub and read it into R.

Answer:
Download from GitHub and then load into R. 
```{r}
metadata<-read.csv("/Users/gordoncuster/Desktop/Micro_Div/metadata.csv")
```
First we need to create a column named Soil. This column will tell us whether the sample was collected from the bulk or rhizosphere component. 
```{r}
#look up the substr command's help page
metadata$Soil<-substr(metadata$Sample_ID, start = 4, stop = 4)

#We create and index with the values currenty in the sheet
index <- c("A", "B")
#the values vector contains what we wish to insert in the pace of the "index"
values <- c("Rhizosphere", "Bulk")

metadata$Soil<- values[match(metadata$Soil, index)]
```

Exercise: Create a column called "Infestation_Stage". This is designated by the first letter in the sample name. H means the sample was collected from a healthy stand, I from an infested stand, and D from a dead stand. In the column called "Infestation_Stage" pull out the first letter, then replace it with "Healthy", "Infested", or "Dead". Use the section above as a template for this. 

Answer:
```{r}
metadata$Infestation_Stage<-substr(metadata$Sample_ID, start = 1, stop = 1)

#We create and index with the values currenty in the sheet
index <- c("H", "D")
#the values vector contains what we wish to insert in the pace of the "index"
values <- c("Healthy", "Dead")

metadata$Infestation_Stage<- values[match(metadata$Infestation_Stage, index)]
```

Lets look at our newly minted metadata sheet.
```{r}
View(metadata)
```

Exercise: Save your metadata file as a .csv to your desktop folder. Save it as a new file from the one your downloaded. 

Answer:
```{r}
write.csv("/Users/gordoncuster/Desktop/Micro_Div/metadata_final.csv")
```

Lastly, suppose you are working with a huge data set. For many of you this will be the case. In order to avoid having to read in your data each and running time consuming code each and every time we can save your environment and reload it when you want to come back. To do so, look in the upper right pane under the environment tab. The save icon here will save your environment. 

Exercise: Save your working environment for use at a later date. Empty your environment and reload your saved data to make sure you are comfortable with this skill. 

Citations and Resources:
1: https://www.r-project.org/ 
2: https://benjjneb.github.io/dada2/index.html
3. https://www.bioconductor.org/